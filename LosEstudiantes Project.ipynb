{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Análisis de Opiniones - Proyecto 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Presentador por:**\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "- **Juan Esteban Cepeda Baena.**\n",
    "- Estudiante de Ciencias de la Computación y Administración de Empresas de la Universidad Nacional de Colombia.\n",
    "- Email: jecepedab@unal.edu.co / juancepeda.gestion@gmail.com\n",
    "- Google Site: https://sites.google.com/view/juancepeda/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducción.\n",
    "\n",
    "---\n",
    "El procesamiento de lenguaje natural (*natural language processing* en inglés) es un campo de la inteligencia artificial y la linguística que estudia las interacciones entre los computadores y el lenguaje humano. Ésta área del conocimiento se ocupa de la formulación e investigación de mecanismos eficaces computacionalmente para la comunicación entre personas y máquinas por medio del lenguaje natural. Los inicios del \"Procesamiento del Lenguaje Natural\" se remontan a finales de los años 40, donde una gran cantidad de investigadores comenzaron a explorar el área conocida como \"Machine Translation (MT)\", la cual exploraba el desarrollo de algoritmos para traducir frases entre el inglés al ruso principalemente. Pocos años más tarde, en 1954, la Universidad de Georgetown en colaboración con IBM, realizaron la primera demostración de traducción automática de más de sesenta frases del ruso al inglés, lo que causó gran conmoción en la opinión pública, e impulsó al desarrollo de esta rama del conocimiento. Así, el procesamiento del lenguaje natural se ha convertido en una de las ramas del conocimiento más importantes para la traducción automática, la categorización de textos, el reconocimiento de spam, el desarrollo de sistemas de diálogos, entre otros (Paroubeck et al., 2019).\n",
    "\n",
    "Una de las aplicaciones más populares del procesamiento del lenguaje natural corresponde al análisis de sentimiento, el cual consiste en identificar y extraer información a partir del análisis de textos u opiniones con el objetivo de clasificarlos de acuerdo con un \"sentimiento\" y/o asignarle una puntuación (para lo cual se emplean métodos de regresión). Así, el presente trabajo aborda la recopilación, procesamiento y análisis de más de 2.000 opiniones extraídas del portal <a href = \"https://losestudiantes.co/\">Los Estudiantes</a>, las cuales corresponden a opiniones publicadas por estudiantes acerca de sus profesores. Cada opinión consiste en un texto y una calificación, además, es importante señalar que este portal almacena información de más de 5.000 docentes que trabajan o han trabajado en la Universidad Nacional de Colombia o en la Universidad de los Andes. En el presente proyecto, se emplean varios modelos de aprendizaje de máquina para clasificación binaria (opinión buena o mala), y para predecir la calificación de una nueva opinión (*Imagen 1*).\n",
    "\n",
    "<img src=\"./Imagenes/problema1.png\"\n",
    " width=\"500\" height = \"400\">\n",
    "<center><i>Imagen 1. Problema planteado para el proyecto. Elaboración propia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Estado del Arte.\n",
    "\n",
    "---\n",
    "Tras años de investigación y desarrollo en materia del \"Procesamiento del Lenguaje Natural\", Khurana, Koli, Khatter y Signh (2017) enuncian un recuento de una gran cantidad de aplicaciones como: traducción automática, categorización de textos, reconocimiento de spam, extracción de información, resumenes, sistemas de diálogo, medicina, entre otros. A continuación, se aborda el estado del arte de cada una de estas aplicaciones:\n",
    "\n",
    "**1. Traducción automática:** Como parte del rápido y gran avance de la globalización a nivel mundial, las necesidades de hacer la información más accesible y disponible han incentivado y exiguido el desarrollo de mecanismos para eliminar los obstáculos de la barrera del idioma. La traducción automática permite traducir frases de un lenguaje a otro con la ayuda de modelos estadísticos como Google Translate. El reto de las tecnologías de traducción automática consiste en preservar el significado de las frases, mientras que traduce palabras y tiempos. Así, en 2016, Google anunció su primera máquina de traducción basada en redes neuronales artificiales y aprendizaje profundo.\n",
    "\n",
    "**2. Categorización de Textos:** Una de las aplicaciones más importantes del procesamiento del lenguaje natural, consiste en clasificar grandes cantidades de informacion como documentos oficiales, reportes de mercado, noticias en distintas categorías. Lo anterior, es altamente utilizado en problemas de detección de spam en correos electrónicos, así como en detección de fraude, permitiendo desarrollar filtros más acertados y eficientes en los tópicos anteriores.\n",
    "\n",
    "**3. Extracción de Información y Análisis de Sentimiento:** Consiste en identificar frases o palabras de interés en información textual. Extraer entidades como nombres, lugares, eventos, fechas, tiempos, precios, entre otros, es un mecanismo útil para resumir informacion, y sobretodo, de gran relevancia en herramientas como los motores de búsquedas, permitiendo realizar búsquedas más específicas y eficientes. Esta habilidad de resumir información a partir del análisis de textos no sólo permite tener la habilidad de reconocer la importancia de la informacion de grandes bases de datos, sino tambien es utilizada para entender de una manera más profunda su significado en términos sentimentales (análisis de sentimiento). Lo anterior, es altamente utilizado en áreas de marketing, psicología de precios, percepción de marcas, servicios y productos, inversiones en la bolsa, entre otros. \n",
    "\n",
    "**4. Sistema de Diálogos:** Los sistemas de diálogo se enfocan en aplicaciones que utilizan niveles fonéticos y léxicos del lenguaje, con la finalidad de producotr sistemas que permiten la interactacion entre máquinas y humanos en lenguajes naturales. Entre los sistemas de diálogo más relevantes se encuentran: Cortana (asistente de Google), Siri (asistente de Apple), Alexa (asistente de Amazon), entre otros.\n",
    "\n",
    "**5. Medicina:** El procesamiento de lenguaje natural en el campo de la medicina busca extraer y resumir información de síntomas, efectos, y respuesta a fármacos por parte de pacientes, con la finalidad de identficiar posible efectos secundarios de cualquier medicina. De esta manera, se busca implementar sistemas multilenguaje robustos, capaces de analizar y comprender las sentencias médicas y preservar el conocimiento de textos en lenguajes independientes.\n",
    "\n",
    "<img src=\"https://www.thinkpalm.com/wp-content/uploads/2019/04/BLOG_NLP-FOR-ARTIFICIAL-INTELLIGENCE_72-1.jpg\"\n",
    " width=\"350\" height = \"230\">\n",
    "<center><i>Imagen 2. Procesamiento de Lenguaje Natural. Recuperado de: <a href = \"https://thinkpalm.com/blogs/natural-language-processing-nlp-artificial-intelligence/\">NLP for Artificial Intelligence</a></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Métodos y Materiales.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 3.1 Métodos.\n",
    "\n",
    "---\n",
    "\n",
    "A continuación se presentan las distintas etapas del desarrollo del proyecto, comenzando por la recolección de datos, su procesamiento, y para finalizar, su análisis. En cada sección se plantea un problema y se explican los métodos que se emplearon para solucionarlo.\n",
    "\n",
    "**A. Recolección de Datos**: Esta etapa del proyecto consiste es desarrollar un algorítmo de *webscraping (Imagen 3)* que permita descargar la información de las opiniones publicadas por los estudiantes, contenidas en la base de datos del portal <a href = \"https://losestudiantes.co/\">Los Estudiantes</a>. Para lograr el objetivo anterior, se emplearon una serie de peticiones al servidor del portal web por medio de la librería *requests*. Después de una breve revisión de la API de la aplicación, se encontró que el link para cargar el perfil de un docente tenía la siguiente estructura: \"https://losestudiantes.co/nombre-universidad/carrera/profesores/nombre-profesor\", por lo que era necesario primero descargar los nombres de los profesores de cada carrera de cada universidad, y esto a su vez requería conocer la lista de carreras ofertadas por cada institución (esto, se podía obtener fácilmente por medio de la siguiente petición al servidor: https://api.losestudiantes.co/universidades/nombre-universidad/programas). \n",
    "\n",
    "Una vez conocida la lista de carreras ofertadas por cada institución, se pasaba a obtener la lista de profesores vinculados con cada carrera, para ello se utilizó la petición \"https://api.losestudiantes.co/universidades/nombre-universidad/programa/nombre-carrera/sample\", la cual retornaba una muestra aleatoria con información de 14 docentes vinculados con la carrera solicitada. Dado que se quería extraer toda la lista docente de cada programa, la misma petición se ejecutó 30 veces con la finalidad de tener la lista completa de profesores. Así, una vez se tenía el código (e.g juan-carlos-quijano-ramirez) de todos los profesores de cada carrera de cada universidad y el código de cada carrera de cada universidad, se extrajo la información de las opiniones publicadas por los estudiantes de cada profesor por medio de la petición al servidor \"https://losestudiantes.co/nombre-universidad/carrera/profesores/nombre-profesor\". Finalmente, se guardó el texto de las opiniones y las calificaciones en un $dataframe$ generado por la librerías Pandas. En la sección 4 del documento (Resultados) se presentan los algoritmos utilizados.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/658/1*kfOsUxggG5wDbDcxgC0Uwg.png\" width=\"400\" height = \"230\">\n",
    "<center><i>Imagen 3. WebScraping. Recuperado de: <a href = \"https://medium.com/@Emmitta/web-scraping-7f87930face4\">WEB SCRAPING</a></i></center>\n",
    "\n",
    "**B. Procesamiento de Datos**: El objetivo de esta etapa es desarrollar un algorítmo para formatear, limpiar y estandarizar el texto de las opiniones obtenidas en la sección anterior. Para ello, se utilizó la librería <a href = \"https://spacy.io/\">Spacy</a> *(Imagen 5)*, la cual es una API de Procesamiento de Lenguaje Natural para Python que incluye modelos estadísticos pre-entrenados, vectores de palabras y soporte de tokenización para más de 50 lenguajes. Adicionalmente, cuenta con modelos de redes neuronales convolucionales de alta velocidad para etiquetado, análisis y reconocimiento de entidades y fácil integración con modelos de aprendizaje profundo. Es un software comercial de código abierto, publicado bajo la licencia MIT (Spacy.io, s.f). De acuerdo con lo anterior, el procesamiento de los textos de las opiniones se realizó en seis partes: \n",
    "\n",
    "1. Inicialización de objeto **nlp** de Spacy con la sentencia a procesar.\n",
    "2. Tokenización de la sentencia: segmentación de la sentencia en palabras y signos de puntuación.\n",
    "3. Eliminación de signos de puntuación y pasar cada palabra a minúscula.\n",
    "4. Lematización: asignación de la forma base de las palabras. Por ejemplo, el lema de \"fue\" es \"es\", y el lema de \"ratas\" es \"rata\".\n",
    "5. Eliminación de palabras que no le aportan información al modelo (Stopwords).\n",
    "6. Eliminación de números.\n",
    "\n",
    "En la imagen 4, se presenta un ejemplo comparativo entre una sentencia sin procesar, y la salida del algoritmo previamente descrito: \n",
    "\n",
    "<img src=\"./Imagenes/comparacion_sentencias.png\">\n",
    "<center><i>Imagen 4. Ejemplo de Procesamiento de Opinión</i></center>\n",
    "\n",
    "Así, siguiendo el procedemiento anterior, se procesaron todos los textos de las opiniones, para más tarde, en la sección de análisis de datos, construir la matriz dispersa (*sparse matrix* en inglés).\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1200/1*qH3Rrck6BGb8vrkNJCS0AQ.png\" width=\"250\" height = \"150\">\n",
    "<center><i>Imagen 5. Librería spaCy para procesamiento de lenguaje natural. Recuperado de: <a href = \"https://medium.com/analytics-vidhya/learn-how-to-use-spacy-for-natural-language-processing-661805d3abae\">Learn how to use spaCy for Natural Language Processing</a></i></center>\n",
    "\n",
    "**C. Análisis de Datos**: El objetivo de esta etapa es entrenar y utilizar una serie de algoritmos de aprendizaje de máquina para predecir la clase de las opiniones (buena o mala, 1/0 respectivamente) y predecir la calificación asignada por el estudiante, como se presentó en la Imagen 1. Para lograr lo anterior, primero se plantea y examina el problema del imbalanceo de datos, para más tarde ejecutar los algoritmos de clasificación y regresión empleados, sobre los cuales se llevan a cabo una serie de mejoras relacionadas con las palabras que mejor predicen la categoría de una opinión. A continuación, se presenta lo anterior detalladamente:\n",
    "\n",
    "**C.1 Imbalanceo de Datos**: El problema de imbalanceo de datos se refiere a una situación en donde el número de observaciones no es el mismo para todas las clases de un conjunto de datos. Lo anterior, puede sesgar la predicción de las clases, favoreciendo a aquellas que son mayoritarias. Para solucionar este problema, se utilizan distintas técnicas de muestreo, a saber: submuestreo (se eliminan observaciones de la clase mayoritaria), generación de datos sintéticos y sobremuestreo (se aumentan las observaciones de la clase minoritaria), y métodos de ponderación de acuerdo al número de observaciones de cada clase (Amsantac.co, 2016). Para solucionar el problema de imbalanceo de datos en este proyecto, se utilizó el método de ponderación, asignándole un mayor peso a la clase minoritaria, con la finalidad de compensar la cantidad de opiniones malas con el número de opiniones buenas extraídas del portal web. \n",
    "\n",
    "**C.2 Entrenamiento de Clasificadores**: Para resolver el problema de clasificación de opiniones entre buenas o malas (Imagen 6), se emplearon dos algoritmos de aprendizaje supervisado: *RandomForestClassifier* y *LinearSVC*. Dado que el conjunto de datos extraídos del portal web Los Estudiantes contenía una calificación de 1 a 5, se determinó que una opinión buena era aquella con una calificación mayor a 3.5, y una opinión mala era aquella con una calificación menor o igual a 3.5. De acuerdo con lo anterior, los datos se etiquetaron con 1 y 0 respectivamente. Ahora bien: para medir el desempeño de los modelos de aprendizaje supervisado empleados, se utilizaron las funciones de métricas incorporadas a la librería *sklearn*. En particular, se computaron tres indicadores, a saber: *precisión*($P$), sensitividad ($S_{t}$) y sensibilidad ($S_{b}$) (para más información, consultar <a href=\"https://en.wikipedia.org/wiki/Sensitivity_and_specificity\">aquí</a>). \n",
    "\n",
    "El modelo de *Random Decision Forests* es un método de aprendizaje de ensamble para clasificación, regresión y otras tareas que operan sobre la construcción de múltiples árboles de decisión que son entrenados simultáneamente y su output corresponde al promedio de las predicción o promedio de las clases (clasificación) de cada uno de los árboles individuales (Para más información, consultar el siguiente <a href = \"https://en.wikipedia.org/wiki/Random_forest\">link</a>) (Tin Kam, 1995). Por otro lado, el modelo de *Support Vector Machine* o en español, Máquinas de vectores de soporte, corresponde a un conjunto de algorítmos de aprendizaje supervisado para clasificación y regresión que computan el mejor hiperplano que separa de forma óptima las observaciones de un *dataset* de acuerdo a su clase. Para más información, consultar <a href = \"https://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte#Idea_b%C3%A1sica\">aquí</a> (Campbell & Colin, 2000).\n",
    "\n",
    "<img src=\"https://homepages.inf.ed.ac.uk/rbf/HIPR2/classb.gif\" width=\"250\" height = \"150\">\n",
    "<center><i>Imagen 6. Ejemplo de Clasificación Binaria. Recuperado de: <a href = \"https://homepages.inf.ed.ac.uk/rbf/HIPR2/classify.htm\">Ejemplo de Clasificación de Observacaciones</a></i></center>\n",
    "\n",
    "**C.3 Entrenamiento de Regresores**: Para resolver el problema de predecir la calificación asignada por un estudiante -dada su opinión acerca del docente- se emplearon dos algoritmos de regresión (Imagen 7), a saber: *RandomForestRegressor* y *Gradient Boosting Regressor*. Para medir el desempeño de ambos modelos de aprendizaje de máquina se utilizó la estadística del coeficiente de determinación ($R^2$), la cual determina la calidad del modelo para replicar los resultados, y la proporción de variación de los resultados que puede explicarse por el modelo (para más información, consultar <a href=\"https://es.wikipedia.org/wiki/Coeficiente_de_determinaci%C3%B3n\">aquí</a>). Ahora bien: el modelo *Gradient Boosting Regressor* construye un modelo aditivo de manera progresiva por etapas; Permite la optimización de funciones arbitrarias de pérdida diferenciable. En cada etapa se ajusta un árbol de regresión en el gradiente negativo de la función de pérdida dada (para más información, consultar <a href = \"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">aquí</a>) (scikit-learn.org, s.f).\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/350px-Linear_regression.svg.png\" width=\"350\" height = \"230\">\n",
    "<center><i>Figura 7. Ejemplo de Regresión Lineal. Recuperado de: <a href = \"https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal\">Wikipedia: Regresión lineal</a></i></center>\n",
    "\n",
    "Por último, cabe señalar que el análisis y discusión de los resultados obtenidos por los clasificadores y los regresores se presenta en la sección 4 del reporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Materiales.\n",
    "\n",
    "---\n",
    "\n",
    "Las herramientas computacionales o librerías utilizadas para el desarrollo del proyecto fueron: 1) Numpy, 2) Pandas, 3) Requests, 4) Matplotlib, 5) Time, 6) Spacy y 7) Sklearn, entre otras. A continuación se explica qué son y cómo fueron utilizadas:\n",
    "\n",
    "1. **Numpy**: es una de las librerías más importante de Python, encargada de incorporar funcionalidades de carácter matemático y vectorial. Esta librería se utilizó para el tratamiento de listas.\n",
    "\n",
    "2. **Pandas**: es una extensión de Numpy desarrollada para la manipulación y análisis de datos en Python. Ofrece estructuras de datos y operaciones para manipular tablas numéricas y series temporales. Esta librería se utilizó para almacenar la información extraída del portal Los Estudiantes, esto es, el texto de las opiniones con su respectiva calificación.\n",
    "\n",
    "3. **Requests**: corresponde a una librería HTTP licenciada por Apache2 y escrita en Python, que permite a los usuarios realizar solicitudes HTTP sin tener que interactuar directamente con URL's o solicitudes POST. Esta librería se utilizó para extraer la base de datos de profesores y opininiones del portal Los Estudiantes, por medio de peticiones al servidor de dicho portal\n",
    "\n",
    "4. **Matplotlib**: es una librería gráfica que permite generar figuras y gráficas de alta calidad, con una gran variedad de formatos y ambientes interactivos.\n",
    "\n",
    "5. **Time**: es una librería instalada por defecto en Python que provee varias funciones para la solución de tareas relacionadas con el tiempo. Para efectos de este proyecto, se utilizó para \"dormir\" el algoritmo de *webscraping*, con la finalidad de no colapsar el servidor de Los Estudiantes con una cantidad indiscriminada de peticiones.\n",
    "\n",
    "6. **Spacy**: es una librería de Procesamiento de Lenguaje Natural para Python que incluye modelos estadísticos pre-entrenados, vectores de palabras y soporte de tokenización para más de 50 lenguajes. Adicionalmente, cuenta con modelos de redes neuronales convolucionales de alta velocidad para etiquetado, análisis y reconocimiento de entidades y fácil integración con modelos de aprendizaje profundo. Como se mencionó en la sección anterior, esta librería se utilizó para el procesamiento del texto de las opiniones.\n",
    "\n",
    "7. **Sklearn**: es una biblioteca de software libre de Python especializada en modelos de aprendizaje de máquina. Esta librería incluye varios algoritmos de clasificación, regresión y análisis de grupos. Esta biblioteca se utilizó para entrenar varios algoritmos de clasificación y regresión para predecir la categoría de las opiniones (buena o mala) y la calificación asignada por el estudiante, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Resultados.\n",
    "\n",
    "---\n",
    "\n",
    "A continuación, se presenta el código del programa distribuído en las tres secciones presentadas en la sección Materiales y Métodos, a saber: recolección de datos, procesamiento de datos y análisis de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Recolección de Datos.**\n",
    "\n",
    "---\n",
    "\n",
    "A continuación, se presentan y explican los algoritmos descritos en apartado de recolección de datos en la sección 2.\n",
    "\n",
    "4.1.1. $getCareers(url)$: Esta función recibe por parámetro la dirección de la petición que se le realiza al servidor del portal web para cargar la lista de códigos de las carreras ofertadas por una universidad. Esta petición se realiza por medio de las funciones de la librería requests. La información que retorna el servidor se procesa, y la función retorna la lista de los códigos de carreras de la universidad solicitada.\n",
    "\n",
    "4.1.2. $getTeachers(url)$: Esta función recibe por parámetro la dirección de la petición que se le realiza al servidor del portal web para cargar la lista de profesores de una facultad (e.g medicina), de una universidad (e.g Universidad de los Andes). Esta petición se realiza por medio de las funciones de la librería requests. La información que retorna el servidor (muestra de información de 12 profesores aleatoriamente) se procesa y se incluye en la lista de profesores. Este procedimiento se repite 30 veces para extraer la mayor cantidad posible de códigos de profesores. Finalmente, la función retorna una lista que contiene el código de todos los profesores de la Univerisdad Nacional de Colombia y la Universidad de los Andes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get careers.\n",
    "def getCareers(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.text\n",
    "    carreras = list()\n",
    "\n",
    "    while(data.find(\"slug\") > 0):\n",
    "        ini_pos = data.find(\"slug\") + 7\n",
    "        contador = ini_pos\n",
    "        name = \"\"\n",
    "        while(data[contador] != ','):\n",
    "            name += data[contador]\n",
    "            contador += 1\n",
    "        name = name[0: len(name) - 1]\n",
    "        if name not in carreras:\n",
    "            carreras.append(name)\n",
    "        data = data[ini_pos + len(name):]\n",
    "    return carreras\n",
    "\n",
    "# Get teacher's careers\n",
    "def getTeachers(url, num_request = 1):\n",
    "    nombres_profesores = list()\n",
    "    for i in range(0, num_request):\n",
    "        r = requests.get(url)\n",
    "        data = r.text\n",
    "\n",
    "        while(data.find(\"slug\") > 0):\n",
    "            ini_pos = data.find(\"slug\") + 7\n",
    "            contador = ini_pos\n",
    "            name = \"\"\n",
    "            while(data[contador] != ','):\n",
    "                name += data[contador]\n",
    "                contador += 1\n",
    "            name = name[0: len(name) - 1]\n",
    "            if name not in nombres_profesores:\n",
    "                nombres_profesores.append(name)\n",
    "            data = data[ini_pos + len(name): ]\n",
    "        time.sleep(0.5)\n",
    "    return nombres_profesores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get teacher's code from all departments of UNAL & UniAndes.\n",
    "profesores_departamento = list()\n",
    "profesores_universidad = list()\n",
    "\n",
    "for university in [\"universidad-nacional\", \"universidad-de-los-andes\"]:\n",
    "    university_url = \"https://api.losestudiantes.co/universidades/\" + university + \"/programas/\"\n",
    "\n",
    "    for career in getCareers(university_url):\n",
    "        \n",
    "        #print(get_careers(university_url))\n",
    "        \n",
    "        career_url = university_url + career + \"/sample\"\n",
    "        career_url = career_url.replace(\"programas\", \"programa\")\n",
    "        \n",
    "        #print(career)\n",
    "        print(career_url)\n",
    "        \n",
    "        profesores_departamento.append(getTeachers(career_url, num_request = 30))\n",
    "        print(career, \" processed...\")\n",
    "        \n",
    "    profesores_universidad.append(profesores_departamento)\n",
    "    print(university, \" processed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show teacher's code from all departments of UNAL & UniAndes.\n",
    "for university in [\"universidad-nacional\", \"universidad-de-los-andes\"]:\n",
    "    university_url = \"https://api.losestudiantes.co/universidades/\" + university + \"/programas/\"\n",
    "\n",
    "    print(\"Universidad: \", university)\n",
    "    print(\"\")\n",
    "    careers = getCareers(university_url)\n",
    "    \n",
    "    for career in careers:\n",
    "        lista_docente = profesores_universidad[dict[university]][careers.index(career)]\n",
    "        print(\"Carrera: \", career)\n",
    "        print(lista_docente)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews and califications of all departments of UNAL & UniAndes.\n",
    "dict = { \"universidad-nacional\": 0, \"universidad-de-los-andes\": 1 }\n",
    "\n",
    "for university in [\"universidad-nacional\", \"universidad-de-los-andes\"]:\n",
    "    \n",
    "    university_url = \"https://api.losestudiantes.co/universidades/\" + university + \"/programas/\"\n",
    "    careers = getCareers(university_url)\n",
    "    \n",
    "    for career in careers:\n",
    "        lista_docente = profesores_universidad[dict[university]][careers.index(career)]\n",
    "        \n",
    "        for profesor in lista_docente:\n",
    "            \n",
    "            if career == \"administracion-de-empresas\": \n",
    "                career = \"administracion-y-contaduria-publica\"\n",
    "            \n",
    "            link_profesor = \"https://losestudiantes.co/\" + university + \"/\" + career + \"/profesores/\" + profesor    \n",
    "            r = requests.get(link_profesor)\n",
    "            data = r.text\n",
    "            \n",
    "            if(data == \"El profesor o el link que buscas no existe\"):\n",
    "                print(\"Enlace roto: \", link_profesor)\n",
    "            \n",
    "            soup = BeautifulSoup(data, \"lxml\")\n",
    "            posts = soup.find_all(\"li\", class_=\"jsx-1682178024 post\")\n",
    "\n",
    "            for p in posts:\n",
    "                opinion = p.find(\"div\", class_ = \"jsx-1682178024 lineBreak\").getText()\n",
    "                if opinion != \"\":\n",
    "                    opinion = opinion.replace(\"Pros\", \"\").replace(\"Cons\", \"\")    \n",
    "                    opiniones.append(opinion)\n",
    "                    calificacion_docente = float(p.find(\"span\", class_ = \"jsx-1682178024 numeroStats\").getText()) \n",
    "                    calificaciones.append(calificacion_docente)\n",
    "\n",
    "            # Sleep the robot.\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            # Print message.\n",
    "            print(\"Procesando... \", profesor)\n",
    "\n",
    "print(\"Finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe with reviews and califications.\n",
    "d = {\"Review\": opiniones, \"Calification\": calificaciones}\n",
    "df = pd.DataFrame(data = d)\n",
    "df.to_csv(\"./opiniones6.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Procesamiento de Datos.**\n",
    "\n",
    "---\n",
    "A continuación, se presentan y explican los algoritmos descritos en apartado de procesamiento de datos en la sección 2.\n",
    "\n",
    "4.2.1. $spacy_{tokenizer}(sentence)$: Esta función recibe por parámetro una sentencia e inicializa el objeto \"nlp\" de Spacy. Paso seguido, segmenta la sentencia en palabras y signos de puntuación, elimina los signos de puntuación; a cada palabra le asigna su forma base, filtra las *stopwords* y elimina los números de la sentencia. Finalmente retorna una lista con las palabras clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    \n",
    "    # Initialize nlp objetct.\n",
    "    sentence = nlp(sentence)\n",
    "    \n",
    "    # Generate list.\n",
    "    mytokens = [token.lemma_.lower().strip() for token in sentence]\n",
    "    mytokens = [token for token in mytokens if token not in stopwords and token not in punctuations]\n",
    "    \n",
    "    # Eliminate numbers.\n",
    "    for word in range(0, len(mytokens)): \n",
    "        try: \n",
    "            if(int(mytokens[word]) > 0):\n",
    "                mytokens[word] = 0\n",
    "        except: \n",
    "            pass  \n",
    "    mytokens = list(dict.fromkeys(mytokens))\n",
    "    try:\n",
    "        mytokens.remove(0)\n",
    "    except:\n",
    "        pass \n",
    "    \n",
    "    # Return array clean message.\n",
    "    return mytokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelente profesora, se aprende un montón y la clase es muy entretenida y usa muchos ejemplos parahacer mas comprensibles los temas.: Entretenido: Parciales un poco complejos\n",
      "\n",
      "Excelente docente, muy recomendada para ver derecho laboral.: Explica los temas con paciencia y con muchos ejemplos.\n",
      "Los parciales son sencillos y corresponden a lo visto en clase.\n",
      "Se abarcan todos los temas del programa.\n",
      "Es muy atenta respondiendo dudas\n",
      "\n",
      "En el area de mercados es la mejor profesora que tiene la facultad.\n",
      "Se entiende todo lo que explica, las clases son entretenidas e interactivas, usa muchos ejemplos y los temas se interiorizan. \n",
      "Su metodología es sencilla.\n",
      "\n",
      ": Facil\n",
      "Entretenido\n",
      "Temas interesantes: Hermético \n",
      "A veces la unica respuesta correcta, es la que el quiere.\n",
      "\n",
      "Es un muy buen profesor, muy didáctico, y hace a los estudiantes muy participes en sus clases\n",
      "\n",
      "Excelente profesor, muy buena dinámica en clases, muy dinámico, propone actividades extracurriculares y explica muy bien todos los temas y conceptos. : Exonera del examen final \n",
      "\n",
      "Execelente profesor. Clases y evaluaciones dinamicas, divertidas y creativas. Sabe de motivacion y incentivos, como un buen lider. No significa que es facil. : Todo en el comentario: a veces hace unos chistes machistas\n",
      "\n",
      "...: El 100% de la materia consiste en la presentación de talleres individuales y grupales\n",
      "Hace las clases amenas y trata de explicar con claridad los temas\n",
      "La materia es extremadamente fácil de aprobar.: Siempre llega 30-40 minutos tarde.\n",
      "Se desconoce la retroalimentación de los talleres.\n",
      "Son muy pocos talleres por semestre, así que la nota de la materia es muy volátil.\n",
      "Falta mucho a clase\n",
      "El programa del curso no se termina pues su ausentismo le impide dictar los temas en su totalidad\n",
      "\n",
      "No es facil entenderle, va muy rapido y no va a la par con las lecturas que deja, de hecho no explica casa nada de las lecturas. Lo bueno es que los parciales deja que se pueda hablar entre compañeros y sacar cuaderno, los talleres son un poco dificiles. : Se puede dejar alta: No se aprende mucho \n",
      "\n",
      "Excelente profesor, se aprende muchísimo y tiene mucha paciencia para explicar. Todo lo ejemplifica y es muy justo con las notas. Hay que hacer 3 parciales, talleres y un trabajo final.\n",
      "Todos los exámenes que hace deja sacar todo, lecturas, computadores y celulares, evalua es que usted sepa hacer un análisis financiero.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data.\n",
    "df = pd.read_csv(\"./opiniones5.csv\")\n",
    "df.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "\n",
    "# Eliminate duplicated rows.\n",
    "df.drop_duplicates(subset = \"Review\", keep = False, inplace = True)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop([\"index\"], axis = 1, inplace = True)\n",
    "\n",
    "# Show df head.\n",
    "for i in range(0, 10):\n",
    "    print(df[\"Review\"][i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries.\n",
    "import spacy\n",
    "from spacy.lang.es.stop_words import STOP_WORDS\n",
    "from spacy.lang.es import Spanish\n",
    "import string\n",
    "\n",
    "# Initialize objects.\n",
    "punctuations = string.punctuation\n",
    "parser = Spanish()\n",
    "stopwords = list(STOP_WORDS)\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Add additional stopwords.\n",
    "additional_stopwords = \"y a e i o u ...\".split()\n",
    "for s in additional_stopwords:\n",
    "    stopwords.append(s)\n",
    "stopwords.remove(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate Corpus.\n",
    "corpus = list()\n",
    "for i in range(0, len(df)):\n",
    "    review = \" \".join(spacy_tokenizer(df[\"Review\"][i]))\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excelente profesor aprender montón clase entretenido parahacer comprensible temer parciales complejo\n",
      "excelente docente recomendar parir derecho laboral explica temer paciencia parcial sencillo corresponder vestir clase abarcar programar atento responder dudar\n",
      "area mercar profesor facultar entender explicar clase entretenido interactivo temer interiorizan metodología sencillo\n",
      "facil entretenido temas interesante hermético unica respuesta correcto querer\n",
      "profesor didáctico estudiante participar clase\n",
      "excelente profesor dinámico clase proponer actividad extracurricular explicar temer concepto exonera examen\n",
      "execelente profesor clases evaluación dinamicas divertir creativo motivacion incentivo comer lider no significar facil comentario chiste machista\n",
      "materia consistir presentación taller individual grupal clase ameno tratar explicar claridad temer extremadamente fácil aprobar llegar minuto tardar desconocer retroalimentación semestre asir noto volátil falta programar cursar no terminar ausentismo impedir dictar totalidad\n",
      "no facil entenderle rapido par lectura dejar explicar casar nadar parcial hablar entrar compañero sacar cuaderno taller dificiles alto aprender\n",
      "excelente profesor aprender muchísimo paciencia parir explicar ejemplificar justar noto parcial taller examen dejar sacar lectura computador celular evalua análisis financiero\n"
     ]
    }
   ],
   "source": [
    "# Print some reviews proccesed.\n",
    "for j in range(0, 10):\n",
    "    print(corpus[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Análisis de Datos.**\n",
    "\n",
    "---\n",
    "En esta etapa se entrenan y utilizan una serie de algoritmos de aprendizaje de máquina para predecir la clase de las opiniones (buena o mala, 1/0 respectivamente) y predecir la calificación asignada por el estudiante. A continuación, se presentan los modelos de clasificación y regresión empleados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "\n",
    "# Feature extraction and model selection.\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Pipeline and transformer.\n",
    "from sklearn.base import TransformerMixin \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer using spaCy.\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3.1 Entrenamiento de Clasificadores.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning Classification models.\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificatorPredictor():\n",
    "    \n",
    "    # Initialize object.\n",
    "    def __init__(self, model_predictor):\n",
    "        \n",
    "        # Set machine learning model.\n",
    "        self.model_predictor = model_predictor\n",
    "        \n",
    "        # Generate sparse matrix.spar\n",
    "        self.vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1, 1), max_features = 1500) \n",
    "        \n",
    "    # Fit the pipe.\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        # Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "        self.pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                         ('vectorizer', self.vectorizer),\n",
    "                         (\"to_dense\", DenseTransformer()),\n",
    "                         ('classifier', self.model_predictor)])\n",
    "        \n",
    "        # Fit our data.\n",
    "        self.pipe.fit(X_train, y_train)\n",
    "        \n",
    "    # Predicting with a test dataset\n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = self.pipe.predict(X_test)\n",
    "        \n",
    "    # Show results.\n",
    "    def showResults(self, X_test):\n",
    "        \n",
    "        counter = 0\n",
    "        \n",
    "        for (sample,pred) in zip(X_test, self.y_pred):\n",
    "            print(\"--\")\n",
    "            print(sample, \"Predicción => \", pred)\n",
    "            \n",
    "            print(\"\")\n",
    "            counter += 1\n",
    "            \n",
    "            if counter >= 5:\n",
    "                break\n",
    "\n",
    "    # Get stats.\n",
    "    def getStats(self, y_test):\n",
    "        cm = metrics.confusion_matrix(y_test, self.y_pred)\n",
    "        \n",
    "        accuracy = (cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])\n",
    "        sensitivity = cm[0][0] / (cm[0][0] + cm[1][0])\n",
    "        specificity = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "        report = [accuracy, sensitivity, specificity]\n",
    "        \n",
    "        return [cm, report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Excelente profesora, se aprende un montón y la...\n",
      "1    Excelente docente, muy recomendada para ver de...\n",
      "2    En el area de mercados es la mejor profesora q...\n",
      "3    : Facil\\nEntretenido\\nTemas interesantes: Herm...\n",
      "4    Es un muy buen profesor, muy didáctico, y hace...\n",
      "Name: Review, dtype: object\n",
      "2419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get reviews & reviews labels.\n",
    "X = df['Review'].copy()\n",
    "print(X.head(5))\n",
    "print(len(X))\n",
    "\n",
    "y = df.iloc[:, 1].values.copy()\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] > 3.5: y[i] = 1\n",
    "    else: y[i] = 0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews:  1628\n",
      "Negative reviews:  791\n"
     ]
    }
   ],
   "source": [
    "# Number of positive review vs negative.\n",
    "positive = 0\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 1: positive += 1\n",
    "print(\"Positive reviews: \", positive)\n",
    "print(\"Negative reviews: \", len(y) - positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607     Clase muy discursiva y dictada casi de memoria...\n",
       "303     La clase se basa en los textos y en la partici...\n",
       "521     En su clase aprendí que el vive en Subachoque,...\n",
       "1070    El es buen profesor, en la magistral hace dorm...\n",
       "816     Excelente docente. Dedica tiempo a calificar, ...\n",
       "                              ...                        \n",
       "960     El profesor maneja y explica muy bien los tema...\n",
       "905     Es muy mala como profesora, no explica, es inc...\n",
       "1096    Es un profesor muy bueno en la parte intuitiva...\n",
       "235     Las clases son super buenas, algunos temas son...\n",
       "1061    Karen es una profesora tesa, Sabe demasiado, s...\n",
       "Name: Review, Length: 1935, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify function.\n",
    "def classify(model):\n",
    "    predictor = ClassificatorPredictor(model)\n",
    "    predictor.fit(X_train, y_train)\n",
    "    predictor.predict(X_test)\n",
    "    \n",
    "    print(\"Model Performance: \")\n",
    "    print(\" \")\n",
    "    \n",
    "    res = predictor.getStats(y_test)\n",
    "    \n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(res[0])\n",
    "    print(\"----------\")\n",
    "    \n",
    "    print(\"Model Stats: \")\n",
    "    print(\"Accuracy: \", res[1][0])\n",
    "    print(\"Sensitivity: \", res[1][1])\n",
    "    print(\"Specificity: \", res[1][2])\n",
    "    print(\"----------\")\n",
    "    \n",
    "    print(\"Results: \")\n",
    "    predictor.showResults(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Máquina de vectores de soporte (*Support Vector Machine*).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      " \n",
      "Confusion Matrix: \n",
      "[[ 97  59]\n",
      " [ 53 275]]\n",
      "----------\n",
      "Model Stats: \n",
      "Accuracy:  0.768595041322314\n",
      "Sensitivity:  0.6466666666666666\n",
      "Specificity:  0.8233532934131736\n",
      "----------\n",
      "Results: \n",
      "--\n",
      ": Incentiva la escritura de textos\n",
      "Fomenta el trabajo en equipo: Es bastante arbitraria con las notas. \n",
      "No se aprende nada\n",
      "No se apropia de sus responsabilidades con respeto a trabajos.\n",
      "El trato con sus estudiantes es muy preferencial.\n",
      "Pone sus situaciones particulares sobre la responsabilidad laboral.\n",
      "Es dispersa con respecto a la asignación de trabajos y a las explicaciones teóricas.   Predicción =>  0.0\n",
      "\n",
      "--\n",
      "Muy buen profesor, se esmera bastante por hacer que los estudiantes entendamos, si tiene que devolverse, se devuelve. En el curso de Sobrevivencia hizo únicamente el primer parcial y los otros fueron exposiciones. Excelente profesor y excelente materia Predicción =>  1.0\n",
      "\n",
      "--\n",
      "no se aprende : no se aprende  Predicción =>  0.0\n",
      "\n",
      "--\n",
      "Excelente profesor y persona. Es gran conocedor de los temas que enseña y está siempre dispuesto a brindar ayuda a los estudiantes  Predicción =>  1.0\n",
      "\n",
      "--\n",
      "Materia sencilla, pero sin el acompañamiento adecuado del profesor y con la a veces absurda exigencia que da el profesor hace la clase ilegible y malentendida. Toca pedir que sea explicito en la interpretación de los problemas (como en el examen final).: Algo bueno o malo es que sus clases son muy prácticas, por lo que enfatiza poco en la teoría: En la entrega de informes (piden informe y al recogerlo tarde no hay suficiente tiempo de retroalimentación, también no dispone de ayuda puesto que es inexistente su presencia en el proceso ya que hasta se va en medio de clase), de gráficas o informes parciales (habla suave y poco claro haciendo difícil la comprensión del objetivo de la gráfica, además de su rapidez en la entrega). Predicción =>  1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine.\n",
    "classify(LinearSVC(penalty = \"l2\", loss = \"squared_hinge\", dual = True, class_weight = {0: 0.6, 1: 0.4}, random_state = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bosques aleatorios de clasificación (*Random Forest Classification*).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      " \n",
      "Confusion Matrix: \n",
      "[[ 87  69]\n",
      " [ 19 309]]\n",
      "----------\n",
      "Model Stats: \n",
      "Accuracy:  0.8181818181818182\n",
      "Sensitivity:  0.8207547169811321\n",
      "Specificity:  0.8174603174603174\n",
      "----------\n",
      "Results: \n",
      "--\n",
      ": Incentiva la escritura de textos\n",
      "Fomenta el trabajo en equipo: Es bastante arbitraria con las notas. \n",
      "No se aprende nada\n",
      "No se apropia de sus responsabilidades con respeto a trabajos.\n",
      "El trato con sus estudiantes es muy preferencial.\n",
      "Pone sus situaciones particulares sobre la responsabilidad laboral.\n",
      "Es dispersa con respecto a la asignación de trabajos y a las explicaciones teóricas.   Predicción =>  0.0\n",
      "\n",
      "--\n",
      "Muy buen profesor, se esmera bastante por hacer que los estudiantes entendamos, si tiene que devolverse, se devuelve. En el curso de Sobrevivencia hizo únicamente el primer parcial y los otros fueron exposiciones. Excelente profesor y excelente materia Predicción =>  1.0\n",
      "\n",
      "--\n",
      "no se aprende : no se aprende  Predicción =>  0.0\n",
      "\n",
      "--\n",
      "Excelente profesor y persona. Es gran conocedor de los temas que enseña y está siempre dispuesto a brindar ayuda a los estudiantes  Predicción =>  1.0\n",
      "\n",
      "--\n",
      "Materia sencilla, pero sin el acompañamiento adecuado del profesor y con la a veces absurda exigencia que da el profesor hace la clase ilegible y malentendida. Toca pedir que sea explicito en la interpretación de los problemas (como en el examen final).: Algo bueno o malo es que sus clases son muy prácticas, por lo que enfatiza poco en la teoría: En la entrega de informes (piden informe y al recogerlo tarde no hay suficiente tiempo de retroalimentación, también no dispone de ayuda puesto que es inexistente su presencia en el proceso ya que hasta se va en medio de clase), de gráficas o informes parciales (habla suave y poco claro haciendo difícil la comprensión del objetivo de la gráfica, además de su rapidez en la entrega). Predicción =>  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier Model.\n",
    "classify(RandomForestClassifier(n_estimators = 100, criterion = \"entropy\", max_depth = 30, class_weight = {0: 0.6, 1: 0.4}, random_state = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3 Entrenamiento de Regresores.**\n",
    "\n",
    "---\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas eleifend gravida neque, nec vulputate turpis imperdiet vel. Suspendisse sagittis vulputate ex sit amet facilisis. Curabitur porttitor dictum urna eget elementum. Mauris et cursus leo, ut aliquet ligula. In hac habitasse platea dictumst. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Nulla rutrum urna at interdum interdum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning Regression Models.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorPredictor():\n",
    "    \n",
    "    # Initialize object.\n",
    "    def __init__(self, model_predictor):\n",
    "        \n",
    "        # Set machine learning model.\n",
    "        self.model_predictor = model_predictor\n",
    "        \n",
    "        # Generate sparse matrix.spar\n",
    "        self.vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, ngram_range=(1, 1), max_features = 1500)\n",
    "        \n",
    "    # Fit the pipe.\n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        # Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "        self.pipe = Pipeline([(\"cleaner\", predictors()),\n",
    "                         ('vectorizer', self.vectorizer),\n",
    "                         (\"to_dense\", DenseTransformer()),\n",
    "                         ('classifier', self.model_predictor)])\n",
    "        \n",
    "        # Fit our data.\n",
    "        self.pipe.fit(X_train, y_train)\n",
    "        \n",
    "    # Predicting with a test dataset\n",
    "    def predict(self, X_test):\n",
    "        self.y_pred = self.pipe.predict(X_test)\n",
    "        self.y_pred = np.around(self.y_pred, 1)\n",
    "        \n",
    "    # Show results.\n",
    "    def showResults(self, X_test, y_test):\n",
    "        \n",
    "        counter = 0\n",
    "        for (sample, pred, real) in zip(X_test, self.y_pred, y_test):\n",
    "            \n",
    "            print(\"--\")\n",
    "            \n",
    "            if(pred > 5): pred = 5\n",
    "            elif(pred < 0): pred = 0\n",
    "            else: pass\n",
    "            \n",
    "            print(sample, \"Predicción => \", pred, \" Real => \", real)\n",
    "            \n",
    "            print(\"\")\n",
    "            \n",
    "            counter += 1\n",
    "            if counter >= 5:\n",
    "                break\n",
    "\n",
    "    # Get stats.\n",
    "    def getStats(self, y_test):\n",
    "        \n",
    "        print(\"Max error: \", metrics.max_error(y_test, self.y_pred))\n",
    "        print(\"Mean absolute error: \", metrics.mean_absolute_error(y_test, self.y_pred))\n",
    "        print(\"Mean squared error: \", metrics.mean_squared_error(y_test, self.y_pred))\n",
    "        #print(\"Mean squared log error: \", metrics.mean_squared_log_error(y_test, self.y_pred))\n",
    "        print(\"Median absolute error: \", metrics.median_absolute_error(y_test, self.y_pred))\n",
    "        print(\"r2 score: \", metrics.r2_score(y_test, self.y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Excelente profesora, se aprende un montón y la...\n",
      "1    Excelente docente, muy recomendada para ver de...\n",
      "2    En el area de mercados es la mejor profesora q...\n",
      "3    : Facil\\nEntretenido\\nTemas interesantes: Herm...\n",
      "4    Es un muy buen profesor, muy didáctico, y hace...\n",
      "Name: Review, dtype: object\n",
      "2419\n",
      "[5.  5.  5.  ... 1.  2.3 4.2]\n"
     ]
    }
   ],
   "source": [
    "# Get reviews & reviews labels.\n",
    "X = df['Review'].copy()\n",
    "print(X.head(5))\n",
    "print(len(X))\n",
    "\n",
    "y = df.iloc[:, 1].values.copy()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607     Clase muy discursiva y dictada casi de memoria...\n",
       "303     La clase se basa en los textos y en la partici...\n",
       "521     En su clase aprendí que el vive en Subachoque,...\n",
       "1070    El es buen profesor, en la magistral hace dorm...\n",
       "816     Excelente docente. Dedica tiempo a calificar, ...\n",
       "                              ...                        \n",
       "960     El profesor maneja y explica muy bien los tema...\n",
       "905     Es muy mala como profesora, no explica, es inc...\n",
       "1096    Es un profesor muy bueno en la parte intuitiva...\n",
       "235     Las clases son super buenas, algunos temas son...\n",
       "1061    Karen es una profesora tesa, Sabe demasiado, s...\n",
       "Name: Review, Length: 1935, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify function.\n",
    "def predict(model):\n",
    "    \n",
    "    predictor = RegressorPredictor(model)\n",
    "    predictor.fit(X_train, y_train)\n",
    "    predictor.predict(X_test)\n",
    "    \n",
    "    print(\"Model Performance: \")\n",
    "    print(\"----\")\n",
    "    predictor.getStats(y_test)\n",
    "    print(\"----\")\n",
    "    print(\" \")\n",
    "    \n",
    "    print(\"Results: \")\n",
    "    predictor.showResults(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresor de Gradiente Ascendente (*Gradient Boosting Regressor*).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "----\n",
      "Max error:  2.8\n",
      "Mean absolute error:  0.7231404958677686\n",
      "Mean squared error:  0.8660330578512396\n",
      "Median absolute error:  0.5999999999999996\n",
      "r2 score:  0.3959570929876235\n",
      "----\n",
      " \n",
      "Results: \n",
      "--\n",
      ": Incentiva la escritura de textos\n",
      "Fomenta el trabajo en equipo: Es bastante arbitraria con las notas. \n",
      "No se aprende nada\n",
      "No se apropia de sus responsabilidades con respeto a trabajos.\n",
      "El trato con sus estudiantes es muy preferencial.\n",
      "Pone sus situaciones particulares sobre la responsabilidad laboral.\n",
      "Es dispersa con respecto a la asignación de trabajos y a las explicaciones teóricas.   Predicción =>  2.4  Real =>  1.5\n",
      "\n",
      "--\n",
      "Muy buen profesor, se esmera bastante por hacer que los estudiantes entendamos, si tiene que devolverse, se devuelve. En el curso de Sobrevivencia hizo únicamente el primer parcial y los otros fueron exposiciones. Excelente profesor y excelente materia Predicción =>  4.8  Real =>  5.0\n",
      "\n",
      "--\n",
      "no se aprende : no se aprende  Predicción =>  3.5  Real =>  1.5\n",
      "\n",
      "--\n",
      "Excelente profesor y persona. Es gran conocedor de los temas que enseña y está siempre dispuesto a brindar ayuda a los estudiantes  Predicción =>  4.8  Real =>  4.9\n",
      "\n",
      "--\n",
      "Materia sencilla, pero sin el acompañamiento adecuado del profesor y con la a veces absurda exigencia que da el profesor hace la clase ilegible y malentendida. Toca pedir que sea explicito en la interpretación de los problemas (como en el examen final).: Algo bueno o malo es que sus clases son muy prácticas, por lo que enfatiza poco en la teoría: En la entrega de informes (piden informe y al recogerlo tarde no hay suficiente tiempo de retroalimentación, también no dispone de ayuda puesto que es inexistente su presencia en el proceso ya que hasta se va en medio de clase), de gráficas o informes parciales (habla suave y poco claro haciendo difícil la comprensión del objetivo de la gráfica, además de su rapidez en la entrega). Predicción =>  2.9  Real =>  2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor.\n",
    "predict(GradientBoostingRegressor(loss = \"ls\", learning_rate = 0.1, criterion = \"friedman_mse\", random_state= 1, n_estimators = 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bosques aleatorios de regresión (*Random Forest Regression*).**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: \n",
      "----\n",
      "Max error:  3.2\n",
      "Mean absolute error:  0.6925619834710744\n",
      "Mean squared error:  0.8802479338842977\n",
      "Median absolute error:  0.5\n",
      "r2 score:  0.38604246563710054\n",
      "----\n",
      " \n",
      "Results: \n",
      "--\n",
      ": Incentiva la escritura de textos\n",
      "Fomenta el trabajo en equipo: Es bastante arbitraria con las notas. \n",
      "No se aprende nada\n",
      "No se apropia de sus responsabilidades con respeto a trabajos.\n",
      "El trato con sus estudiantes es muy preferencial.\n",
      "Pone sus situaciones particulares sobre la responsabilidad laboral.\n",
      "Es dispersa con respecto a la asignación de trabajos y a las explicaciones teóricas.   Predicción =>  2.4  Real =>  1.5\n",
      "\n",
      "--\n",
      "Muy buen profesor, se esmera bastante por hacer que los estudiantes entendamos, si tiene que devolverse, se devuelve. En el curso de Sobrevivencia hizo únicamente el primer parcial y los otros fueron exposiciones. Excelente profesor y excelente materia Predicción =>  4.7  Real =>  5.0\n",
      "\n",
      "--\n",
      "no se aprende : no se aprende  Predicción =>  3.6  Real =>  1.5\n",
      "\n",
      "--\n",
      "Excelente profesor y persona. Es gran conocedor de los temas que enseña y está siempre dispuesto a brindar ayuda a los estudiantes  Predicción =>  4.9  Real =>  4.9\n",
      "\n",
      "--\n",
      "Materia sencilla, pero sin el acompañamiento adecuado del profesor y con la a veces absurda exigencia que da el profesor hace la clase ilegible y malentendida. Toca pedir que sea explicito en la interpretación de los problemas (como en el examen final).: Algo bueno o malo es que sus clases son muy prácticas, por lo que enfatiza poco en la teoría: En la entrega de informes (piden informe y al recogerlo tarde no hay suficiente tiempo de retroalimentación, también no dispone de ayuda puesto que es inexistente su presencia en el proceso ya que hasta se va en medio de clase), de gráficas o informes parciales (habla suave y poco claro haciendo difícil la comprensión del objetivo de la gráfica, además de su rapidez en la entrega). Predicción =>  2.5  Real =>  2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Regression.\n",
    "predict(RandomForestRegressor(n_estimators = 100, criterion = \"mse\", max_depth = 30, random_state = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Discusión.\n",
    "\n",
    "---\n",
    "\n",
    "Como se mencionó en la sección 2 del proyecto, la ponderación de clases como mecanismo para solventar el imbalanceo de datos entre la clase mayoritaria (opiniones \"buenas\") vs la clase minoritaria (opiniones \"malas\") permitió obtener un incremento significativo tanto en la sensitividad como la sensibilidad de los modelos de clasificación utilizados (tras realizar varios intentos, se determinó que una ponderación del 60% para la clase minoritaria y un 40% para la clase mayoritaria permitía maximizar estos ratios). En el caso de los resultados obtenidos por la máquina de vectores de soporte, a pesar del ajuste de distintos hiperparámetros, no fue posible obtener una sensitividad mayor al 70% (lo anterior, puede deberse a la poca linearidad que caracteriza al problema). En contraste, el modelo de bosques de árboles de decisión para la clasificación de observaciones obtuvo excelentes resultados, logrando una precisión, sensitividad y sensibildidad mayores al 80% (dos de las características fundamentales para lograr este desempeño fueron la selección del peso de las clases y la máxima profundidad [30] que se permitió para los árboles). Adicionalmente, como criterio de clasificación se utilizó la *entropía*. \n",
    "\n",
    "Por otro lado, para los modelos de regresión resultó crítico el reducido tamaño del conjunto de datos (un poco más de 2.000 observaciones) y la poca exploración de vari, lo que se reflejó en las medidas de desempeño de los dos modelos de aprendizaje de máquina empleados para esta tarea, cuyos $R^2$ no lograron pasar de 0.4. Lo anterior, impedía que los regresores se entrenaran lo suficiente, resultando en predicciones muy alejadas de las califaciones reales. Adicionalmente, otro factor que influyó en la pobre capacidad predictiva de los modelos, fue el hecho de no reconocer qué variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusiones.\n",
    "\n",
    "---\n",
    "\n",
    "**I)** Como parte de futuros trabajos de investigación en esta materia, se debe trabajar en mejorar el procesamiento de los textos de las opiniones, esto es, desarrollar mejores algorítmos para los procesos de lematización y tokenización de las sentencias. Asímismo, es importante incluir un componente que analice la similaridad de las palabras y el contexto de las sentencias. Lo anterior, permitirá desarrollar algoritmos de clasificación y regresión más eficaces y acertados.\n",
    "\n",
    "**II)** Para futuros avances de este proyecto, se debe desarrollar un mecanismo para medir de manera precisa el nivel de relevancia de cada palabra dentro del modelo. Lo anterior, con la finalidad de eliminar las palabras que poco le aportan al mismo al momento de clasificar la categoría de nuevas opiniones o predecir la calificación asignada por un estudiante. Adicionalmente, se deben explorar nuevos métodos de aprendizaje de máquina de regresión y clasificación, enfatizando en métodos de ensamble (para incrementar la probabilidad de tener predicciones y clasificaciones correctas), así como el ajuste óptimo de sus parámetros para aumentar el nivel de acertividad de los modelos.\n",
    "\n",
    "**III)** La base de datos utilizada para este proyecto, tan sólo incluía un poco más de 2.000 opiniones, lo que resultó en una cantidad insuficiente de observaciones para entrenar a los algoritmos de clasificación y regresión. Por esta razón, y como parte de futuros avances de este proyecto, se podría desarrollar un módulo que le permita a los modelos de aprendizaje de máquina extraer nuevas opiniones del portal y entrenarse en tiempo real. Esto, con la finalidad de obtener mejores regresores y clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Bibliografía.\n",
    "\n",
    "---\n",
    "\n",
    "1. Amsantac.co. (20 de septiembre del 2016). ¿Por qué es importante trabajar con datos balanceados para clasificación? Recuperado de: http://amsantac.co/blog/es/2016/09/20/balanced-image-classification-r-es.html\n",
    "\n",
    "2. Campbell & Colin (2000). Support Vector Machines: Hype or Hallelujah? SIGKDD Explorations. 2 (2): 1–13. Recuperado de: https://dl.acm.org/citation.cfm?doid=380995.380999\n",
    "\n",
    "3. Ho, Tin Kam (1995). Random Decision Forests. Proceedings of the 3rd international Conference on Document Analysis and Recognition, Montreal, QC, 14-16 Agosto 1995. pp. 278-282. Recuperado de: https://web.archive.org/web/20160417030218/http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf\n",
    "\n",
    "4. Mariani J, Francopoulo G & Paroubek P. (7 de febrero del 2019) The NLP4NLP Corpus (I): 50 Years of Publication, Collaboration and Citation in Speech and Language Processing. Recuperado de https://www.frontiersin.org/articles/10.3389/frma.2018.00036/full\n",
    "\n",
    "5. Khurana. D, Koli. A, Khatter. K, Singh S. (2017). Natural Language Processing: State of The Art, Current Trends and Challenges. Recuperado de: https://www.researchgate.net/publication/319164243_Natural_Language_Processing_State_of_The_Art_Current_Trends_and_Challenges.\n",
    "\n",
    "6. Scikit-learn.org (s.f). Gradient Tree Boosting. Recuperado de: https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
